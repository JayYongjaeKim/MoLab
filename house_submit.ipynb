{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 88657,
          "databundleVersionId": 10158206,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "hooooome",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayYongjaeKim/MoLab/blob/main/house_submit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "Fx7G8uXsep5x"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "aiffel_ds_3_house_prices_path = kagglehub.competition_download('aiffel-ds-3-house-prices')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "PweFLcoQep5x"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-11-15T07:07:02.788344Z",
          "iopub.execute_input": "2024-11-15T07:07:02.788801Z",
          "iopub.status.idle": "2024-11-15T07:07:02.798624Z",
          "shell.execute_reply.started": "2024-11-15T07:07:02.788749Z",
          "shell.execute_reply": "2024-11-15T07:07:02.79737Z"
        },
        "trusted": true,
        "id": "xRzHb5gzep5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/kaggle/input/aiffel-ds-3-house-prices/train.csv'\n",
        "test_path = '/kaggle/input/aiffel-ds-3-house-prices/test.csv'\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "test = pd.read_csv(test_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-15T07:08:44.61391Z",
          "iopub.execute_input": "2024-11-15T07:08:44.614359Z",
          "iopub.status.idle": "2024-11-15T07:08:44.654265Z",
          "shell.execute_reply.started": "2024-11-15T07:08:44.614315Z",
          "shell.execute_reply": "2024-11-15T07:08:44.652996Z"
        },
        "trusted": true,
        "id": "z4ZL0Va1ep5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "import optuna\n",
        "\n",
        "# Handle missing values\n",
        "threshold = 0.5\n",
        "train = train.drop(columns=train.columns[train.isnull().mean() > threshold])\n",
        "test = test.drop(columns=test.columns[test.isnull().mean() > threshold])\n",
        "\n",
        "for col in train.select_dtypes(include='number').columns:\n",
        "    train[col] = train[col].fillna(train[col].median())\n",
        "    if col in test.columns:\n",
        "        test[col] = test[col].fillna(test[col].median())\n",
        "\n",
        "for col in train.select_dtypes(include='object').columns:\n",
        "    train[col] = train[col].fillna(train[col].mode()[0])\n",
        "    if col in test.columns:\n",
        "        test[col] = test[col].fillna(test[col].mode()[0])\n",
        "\n",
        "# Apply log transformation to SalePrice\n",
        "train['SalePrice'] = np.log1p(train['SalePrice'])\n",
        "\n",
        "# Feature engineering\n",
        "train['TotalSF'] = train['TotalBsmtSF'] + train['1stFlrSF'] + train['2ndFlrSF']\n",
        "test['TotalSF'] = test['TotalBsmtSF'] + test['1stFlrSF'] + test['2ndFlrSF']\n",
        "\n",
        "train['Age'] = train['YrSold'] - train['YearBuilt']\n",
        "test['Age'] = test['YrSold'] - test['YearBuilt']\n",
        "\n",
        "train['RemodAge'] = train['YrSold'] - train['YearRemodAdd']\n",
        "test['RemodAge'] = test['YrSold'] - test['YearRemodAdd']\n",
        "\n",
        "# Encode categorical variables\n",
        "combined = pd.concat([train.drop(columns=['SalePrice']), test], axis=0)\n",
        "\n",
        "for col in combined.select_dtypes(include='object').columns:\n",
        "    combined[col] = combined[col].astype('category').cat.codes\n",
        "\n",
        "train_processed = combined.iloc[:len(train), :].copy()\n",
        "test_processed = combined.iloc[len(train):, :].copy()\n",
        "\n",
        "X = train_processed\n",
        "y = train['SalePrice']\n",
        "X_test = test_processed\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Define objective function for Optuna\n",
        "def objective(trial, model_name):\n",
        "    if model_name == 'xgb':\n",
        "        params = {\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 500, 1500),\n",
        "            'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),\n",
        "        }\n",
        "        model = xgb.XGBRegressor(**params)\n",
        "\n",
        "    elif model_name == 'lgb':\n",
        "        params = {\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 500, 1500),\n",
        "            'num_leaves': trial.suggest_int('num_leaves', 31, 255),\n",
        "            'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),\n",
        "        }\n",
        "        model = lgb.LGBMRegressor(**params)\n",
        "\n",
        "    elif model_name == 'cb':\n",
        "        params = {\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "            'depth': trial.suggest_int('depth', 3, 10),\n",
        "            'iterations': trial.suggest_int('iterations', 500, 1500),\n",
        "            'random_strength': trial.suggest_float('random_strength', 0.5, 2.0),\n",
        "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.1, 1.0),\n",
        "        }\n",
        "        model = cb.CatBoostRegressor(**params, verbose=0)\n",
        "\n",
        "    scores = []\n",
        "    for train_idx, val_idx in kf.split(X_scaled):\n",
        "        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "        model.fit(X_train, y_train)\n",
        "        y_val_pred = model.predict(X_val)\n",
        "        scores.append(mean_squared_error(y_val, y_val_pred, squared=False))\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "# Optimization for each model\n",
        "def optimize_model(model_name):\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(lambda trial: objective(trial, model_name), n_trials=50)\n",
        "    print(f\"Best parameters for {model_name}: {study.best_params}\")\n",
        "    print(f\"Best RMSE for {model_name}: {study.best_value}\")\n",
        "    return study.best_params\n",
        "\n",
        "# Run optimization\n",
        "xgb_best_params = optimize_model('xgb')\n",
        "lgb_best_params = optimize_model('lgb')\n",
        "cb_best_params = optimize_model('cb')\n",
        "\n",
        "# Fit final models with optimized parameters\n",
        "xgb_model = xgb.XGBRegressor(**xgb_best_params)\n",
        "lgb_model = lgb.LGBMRegressor(**lgb_best_params)\n",
        "cb_model = cb.CatBoostRegressor(**cb_best_params, verbose=0)\n",
        "\n",
        "xgb_model.fit(X_scaled, y)\n",
        "lgb_model.fit(X_scaled, y)\n",
        "cb_model.fit(X_scaled, y)\n",
        "\n",
        "# Predictions (with inverse log transformation)\n",
        "xgb_preds = np.expm1(xgb_model.predict(X_test_scaled))\n",
        "lgb_preds = np.expm1(lgb_model.predict(X_test_scaled))\n",
        "cb_preds = np.expm1(cb_model.predict(X_test_scaled))\n",
        "\n",
        "# Weighted ensemble predictions\n",
        "final_preds = (0.4 * cb_preds + 0.3 * xgb_preds + 0.3 * lgb_preds)\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({'Id': test['Id'], 'SalePrice': final_preds})\n",
        "submission.to_csv('submission_optimized_tuned.csv', index=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-15T07:08:45.98586Z",
          "iopub.execute_input": "2024-11-15T07:08:45.98633Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "qIVoZS0eep5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-15T08:05:57.405118Z",
          "iopub.execute_input": "2024-11-15T08:05:57.406243Z",
          "iopub.status.idle": "2024-11-15T08:05:57.808864Z",
          "shell.execute_reply.started": "2024-11-15T08:05:57.406191Z",
          "shell.execute_reply": "2024-11-15T08:05:57.807055Z"
        },
        "trusted": true,
        "id": "GTSQctNmep5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KguRmkF7ep5z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}